{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'yelp': '../data/yelp_labelled.txt',\n",
    "                         'amazon': '../data/amazon_cells_labelled.txt',\n",
    "                         'imdb': '../data/imdb_labelled.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source\n",
    "    df_list.append(df)\n",
    "    \n",
    "df=pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label source\n",
       "0                             Wow... Loved this place.      1   yelp\n",
       "1                                   Crust is not good.      0   yelp\n",
       "2            Not tasty and the texture was just nasty.      0   yelp\n",
       "3    Stopped by during the late May bank holiday of...      1   yelp\n",
       "4    The selection on the menu was great and so wer...      1   yelp\n",
       "..                                                 ...    ...    ...\n",
       "743  I just got bored watching Jessice Lange take h...      0   imdb\n",
       "744  Unfortunately, any virtue in this film's produ...      0   imdb\n",
       "745                   In a word, it is embarrassing.        0   imdb\n",
       "746                               Exceptionally bad!        0   imdb\n",
       "747  All in all its an insult to one's intelligence...      0   imdb\n",
       "\n",
       "[2748 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex the text features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eg:\n",
    "sentences = ['Join likes ice cream', 'John hates chocolate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'join': 5, 'likes': 6, 'ice': 3, 'cream': 1, 'john': 4, 'hates': 2, 'chocolate': 0}\n",
      "[[0 1 0 1 0 1 1]\n",
      " [1 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0, lowercase=True)\n",
    "vectorizer.fit(sentences)\n",
    "print(vectorizer.vocabulary_)\n",
    "print(vectorizer.transform(sentences).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split the dataset \n",
    "df_yelp = df[df['source'] == 'yelp']\n",
    "sentences = df_yelp['sentence'].values\n",
    "y = df_yelp['label'].values\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)\n",
    "# print(sentences_train)\n",
    "# print(sentences_test)\n",
    "# print(y_train)\n",
    "# print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test = vectorizer.transform(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(750, 1714)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 1714)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use some logisticRegression for a try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare three different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataprocess():\n",
    "    def __init__(self, data, source):\n",
    "        self.df = data[data['source'] == source]\n",
    "        self.sentences = self.df['sentence'].values\n",
    "        self.y = self.df['label'].values\n",
    "        \n",
    "    def train_test_data_split(self):\n",
    "        sentences_train, sentences_test, y_train, y_test = train_test_split(self.sentences, \n",
    "                                                                                                                 self.y, \n",
    "                                                                                                                 test_size=0.25, \n",
    "                                                                                                                 random_state=1000)\n",
    "        return sentences_train, sentences_test, y_train, y_test      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountTheVectorizer():\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        \n",
    "    def fit_ve(self, sentences_train, sentences_test):\n",
    "        self.vectorizer.fit(sentences_train)\n",
    "        X_train = self.vectorizer.transform(sentences_train)\n",
    "        X_test = self.vectorizer.transform(sentences_test)\n",
    "    \n",
    "        return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classfier():\n",
    "    def __init__(self):\n",
    "        self.classfier = LogisticRegression()\n",
    "    \n",
    "    def fit_model(self, X_train, y_train, X_test, y_test):\n",
    "        self.classfier.fit(X_train, y_train)\n",
    "        score = self.classfier.score(X_test, y_test)\n",
    "        \n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for yelp data: 0.796\n",
      "Accuracy for amazon data: 0.796\n",
      "Accuracy for imdb data: 0.7486631016042781\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    for source in df['source'].unique():\n",
    "        data = Dataprocess(df, source)\n",
    "        \n",
    "        sentences_train, sentences_test, y_train, y_test =  data.train_test_data_split()\n",
    "        \n",
    "        vectorizer = CountTheVectorizer()\n",
    "        X_train, X_test = vectorizer.fit_ve(sentences_train, sentences_test)\n",
    "        \n",
    "        classfier = Classfier()\n",
    "        score = classfier.fit_model(X_train, y_train, X_test, y_test)\n",
    "        print('Accuracy for {} data: {}'.format(source, score))\n",
    "        \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nerul network model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>I just got bored watching Jessice Lange take h...</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Unfortunately, any virtue in this film's produ...</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>In a word, it is embarrassing.</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>Exceptionally bad!</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>All in all its an insult to one's intelligence...</td>\n",
       "      <td>0</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2748 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  label source\n",
       "0                             Wow... Loved this place.      1   yelp\n",
       "1                                   Crust is not good.      0   yelp\n",
       "2            Not tasty and the texture was just nasty.      0   yelp\n",
       "3    Stopped by during the late May bank holiday of...      1   yelp\n",
       "4    The selection on the menu was great and so wer...      1   yelp\n",
       "..                                                 ...    ...    ...\n",
       "743  I just got bored watching Jessice Lange take h...      0   imdb\n",
       "744  Unfortunately, any virtue in this film's produ...      0   imdb\n",
       "745                   In a word, it is embarrassing.        0   imdb\n",
       "746                               Exceptionally bad!        0   imdb\n",
       "747  All in all its an insult to one's intelligence...      0   imdb\n",
       "\n",
       "[2748 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple NN \n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, df):\n",
    "        self.sentences = df.sentence.values\n",
    "        self.label = df.label.values\n",
    "        \n",
    "    def train_test_data_split(self):\n",
    "        sentences_train, sentences_test, y_train, y_test = train_test_split(self.sentences, self.label, test_size=0.25, random_state=1000)\n",
    "        return sentences_train, sentences_test, y_train, y_test  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataLoader(df)\n",
    "sentences_train, sentences_test, y_train, y_test = data.train_test_data_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountTheVectorizer()\n",
    "X_train, X_test = vectorizer.fit_ve(sentences_train, sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert it into np.array\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4506"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of features \n",
    "input_dim = X_train.shape[1]\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                288448    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 290,561\n",
      "Trainable params: 290,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build and compile\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(64, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='sigmoid'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.7605e-07 - accuracy: 1.0000 - val_loss: 2.0580 - val_accuracy: 0.7991\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.6806e-07 - accuracy: 1.0000 - val_loss: 2.0596 - val_accuracy: 0.7991\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.6017e-07 - accuracy: 1.0000 - val_loss: 2.0614 - val_accuracy: 0.7991\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.5233e-07 - accuracy: 1.0000 - val_loss: 2.0629 - val_accuracy: 0.7991\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.4460e-07 - accuracy: 1.0000 - val_loss: 2.0645 - val_accuracy: 0.7991\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.3694e-07 - accuracy: 1.0000 - val_loss: 2.0662 - val_accuracy: 0.7991\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.2936e-07 - accuracy: 1.0000 - val_loss: 2.0679 - val_accuracy: 0.7991\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.2184e-07 - accuracy: 1.0000 - val_loss: 2.0696 - val_accuracy: 0.7991\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.1440e-07 - accuracy: 1.0000 - val_loss: 2.0712 - val_accuracy: 0.7991\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 7.0703e-07 - accuracy: 1.0000 - val_loss: 2.0727 - val_accuracy: 0.7991\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.9968e-07 - accuracy: 1.0000 - val_loss: 2.0743 - val_accuracy: 0.7991\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.9247e-07 - accuracy: 1.0000 - val_loss: 2.0760 - val_accuracy: 0.7991\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.8523e-07 - accuracy: 1.0000 - val_loss: 2.0778 - val_accuracy: 0.7991\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.7811e-07 - accuracy: 1.0000 - val_loss: 2.0796 - val_accuracy: 0.7991\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.7105e-07 - accuracy: 1.0000 - val_loss: 2.0813 - val_accuracy: 0.7991\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.6411e-07 - accuracy: 1.0000 - val_loss: 2.0829 - val_accuracy: 0.7991\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 6.5721e-07 - accuracy: 1.0000 - val_loss: 2.0844 - val_accuracy: 0.7991\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.5048e-07 - accuracy: 1.0000 - val_loss: 2.0863 - val_accuracy: 0.7991\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.4378e-07 - accuracy: 1.0000 - val_loss: 2.0879 - val_accuracy: 0.7991\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.3721e-07 - accuracy: 1.0000 - val_loss: 2.0892 - val_accuracy: 0.7991\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.3074e-07 - accuracy: 1.0000 - val_loss: 2.0913 - val_accuracy: 0.7991\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.2422e-07 - accuracy: 1.0000 - val_loss: 2.0927 - val_accuracy: 0.7991\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 6.1784e-07 - accuracy: 1.0000 - val_loss: 2.0944 - val_accuracy: 0.7991\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.1148e-07 - accuracy: 1.0000 - val_loss: 2.0961 - val_accuracy: 0.7991\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 6.0521e-07 - accuracy: 1.0000 - val_loss: 2.0977 - val_accuracy: 0.7991\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.9900e-07 - accuracy: 1.0000 - val_loss: 2.0993 - val_accuracy: 0.7991\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.9282e-07 - accuracy: 1.0000 - val_loss: 2.1008 - val_accuracy: 0.7991\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.8671e-07 - accuracy: 1.0000 - val_loss: 2.1027 - val_accuracy: 0.7991\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.8065e-07 - accuracy: 1.0000 - val_loss: 2.1042 - val_accuracy: 0.7991\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.7465e-07 - accuracy: 1.0000 - val_loss: 2.1058 - val_accuracy: 0.7991\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.6866e-07 - accuracy: 1.0000 - val_loss: 2.1076 - val_accuracy: 0.7991\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.6278e-07 - accuracy: 1.0000 - val_loss: 2.1092 - val_accuracy: 0.7991\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.5689e-07 - accuracy: 1.0000 - val_loss: 2.1109 - val_accuracy: 0.7991\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.5108e-07 - accuracy: 1.0000 - val_loss: 2.1126 - val_accuracy: 0.7991\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.4533e-07 - accuracy: 1.0000 - val_loss: 2.1145 - val_accuracy: 0.7991\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.3973e-07 - accuracy: 1.0000 - val_loss: 2.1160 - val_accuracy: 0.7991\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.3417e-07 - accuracy: 1.0000 - val_loss: 2.1175 - val_accuracy: 0.7991\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.2871e-07 - accuracy: 1.0000 - val_loss: 2.1192 - val_accuracy: 0.7991\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.2329e-07 - accuracy: 1.0000 - val_loss: 2.1207 - val_accuracy: 0.7991\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.1796e-07 - accuracy: 1.0000 - val_loss: 2.1225 - val_accuracy: 0.7991\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.1272e-07 - accuracy: 1.0000 - val_loss: 2.1237 - val_accuracy: 0.8006\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.0751e-07 - accuracy: 1.0000 - val_loss: 2.1257 - val_accuracy: 0.7991\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 5.0224e-07 - accuracy: 1.0000 - val_loss: 2.1273 - val_accuracy: 0.7991\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.9711e-07 - accuracy: 1.0000 - val_loss: 2.1287 - val_accuracy: 0.8006\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.9203e-07 - accuracy: 1.0000 - val_loss: 2.1303 - val_accuracy: 0.8006\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.8700e-07 - accuracy: 1.0000 - val_loss: 2.1322 - val_accuracy: 0.8006\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.8200e-07 - accuracy: 1.0000 - val_loss: 2.1338 - val_accuracy: 0.8006\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.7702e-07 - accuracy: 1.0000 - val_loss: 2.1355 - val_accuracy: 0.8006\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.7215e-07 - accuracy: 1.0000 - val_loss: 2.1370 - val_accuracy: 0.8006\n",
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.6728e-07 - accuracy: 1.0000 - val_loss: 2.1384 - val_accuracy: 0.8006\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.6245e-07 - accuracy: 1.0000 - val_loss: 2.1402 - val_accuracy: 0.8006\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.5769e-07 - accuracy: 1.0000 - val_loss: 2.1421 - val_accuracy: 0.8006\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.5295e-07 - accuracy: 1.0000 - val_loss: 2.1435 - val_accuracy: 0.8006\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.4823e-07 - accuracy: 1.0000 - val_loss: 2.1452 - val_accuracy: 0.8006\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.4361e-07 - accuracy: 1.0000 - val_loss: 2.1471 - val_accuracy: 0.8006\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.3895e-07 - accuracy: 1.0000 - val_loss: 2.1485 - val_accuracy: 0.8006\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 9ms/step - loss: 4.3437e-07 - accuracy: 1.0000 - val_loss: 2.1502 - val_accuracy: 0.8006\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.2982e-07 - accuracy: 1.0000 - val_loss: 2.1519 - val_accuracy: 0.8006\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.2531e-07 - accuracy: 1.0000 - val_loss: 2.1537 - val_accuracy: 0.8006\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.2090e-07 - accuracy: 1.0000 - val_loss: 2.1552 - val_accuracy: 0.8006\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.1662e-07 - accuracy: 1.0000 - val_loss: 2.1568 - val_accuracy: 0.8006\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.1234e-07 - accuracy: 1.0000 - val_loss: 2.1584 - val_accuracy: 0.8006\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.0814e-07 - accuracy: 1.0000 - val_loss: 2.1602 - val_accuracy: 0.8006\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 4.0402e-07 - accuracy: 1.0000 - val_loss: 2.1616 - val_accuracy: 0.8006\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.9988e-07 - accuracy: 1.0000 - val_loss: 2.1633 - val_accuracy: 0.8006\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.9584e-07 - accuracy: 1.0000 - val_loss: 2.1649 - val_accuracy: 0.8006\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.9180e-07 - accuracy: 1.0000 - val_loss: 2.1665 - val_accuracy: 0.8006\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.8782e-07 - accuracy: 1.0000 - val_loss: 2.1681 - val_accuracy: 0.8006\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.8389e-07 - accuracy: 1.0000 - val_loss: 2.1696 - val_accuracy: 0.8006\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.7998e-07 - accuracy: 1.0000 - val_loss: 2.1712 - val_accuracy: 0.8006\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.7611e-07 - accuracy: 1.0000 - val_loss: 2.1727 - val_accuracy: 0.8006\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.7226e-07 - accuracy: 1.0000 - val_loss: 2.1744 - val_accuracy: 0.8006\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.6849e-07 - accuracy: 1.0000 - val_loss: 2.1763 - val_accuracy: 0.8006\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.6475e-07 - accuracy: 1.0000 - val_loss: 2.1777 - val_accuracy: 0.8006\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.6099e-07 - accuracy: 1.0000 - val_loss: 2.1794 - val_accuracy: 0.8006\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.5729e-07 - accuracy: 1.0000 - val_loss: 2.1809 - val_accuracy: 0.8006\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.5365e-07 - accuracy: 1.0000 - val_loss: 2.1825 - val_accuracy: 0.8006\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.4999e-07 - accuracy: 1.0000 - val_loss: 2.1841 - val_accuracy: 0.8006\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.4641e-07 - accuracy: 1.0000 - val_loss: 2.1857 - val_accuracy: 0.8006\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.4284e-07 - accuracy: 1.0000 - val_loss: 2.1875 - val_accuracy: 0.8006\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.3933e-07 - accuracy: 1.0000 - val_loss: 2.1891 - val_accuracy: 0.8006\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.3581e-07 - accuracy: 1.0000 - val_loss: 2.1907 - val_accuracy: 0.8006\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.3235e-07 - accuracy: 1.0000 - val_loss: 2.1919 - val_accuracy: 0.8006\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.2888e-07 - accuracy: 1.0000 - val_loss: 2.1939 - val_accuracy: 0.8006\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.2547e-07 - accuracy: 1.0000 - val_loss: 2.1956 - val_accuracy: 0.8006\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.2207e-07 - accuracy: 1.0000 - val_loss: 2.1971 - val_accuracy: 0.8006\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.1871e-07 - accuracy: 1.0000 - val_loss: 2.1989 - val_accuracy: 0.8006\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.1538e-07 - accuracy: 1.0000 - val_loss: 2.2004 - val_accuracy: 0.8006\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.1208e-07 - accuracy: 1.0000 - val_loss: 2.2021 - val_accuracy: 0.8006\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.0878e-07 - accuracy: 1.0000 - val_loss: 2.2038 - val_accuracy: 0.8006\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.0551e-07 - accuracy: 1.0000 - val_loss: 2.2054 - val_accuracy: 0.8006\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.0230e-07 - accuracy: 1.0000 - val_loss: 2.2071 - val_accuracy: 0.8006\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.9919e-07 - accuracy: 1.0000 - val_loss: 2.2088 - val_accuracy: 0.8006\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.9614e-07 - accuracy: 1.0000 - val_loss: 2.2103 - val_accuracy: 0.8006\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.9313e-07 - accuracy: 1.0000 - val_loss: 2.2119 - val_accuracy: 0.8006\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.9020e-07 - accuracy: 1.0000 - val_loss: 2.2136 - val_accuracy: 0.8006\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 2.8725e-07 - accuracy: 1.0000 - val_loss: 2.2151 - val_accuracy: 0.8020\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 2.8438e-07 - accuracy: 1.0000 - val_loss: 2.2166 - val_accuracy: 0.8006\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.8154e-07 - accuracy: 1.0000 - val_loss: 2.2182 - val_accuracy: 0.8006\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - ETA: 0s - loss: 2.8180e-07 - accuracy: 1.00 - 0s 8ms/step - loss: 2.7870e-07 - accuracy: 1.0000 - val_loss: 2.2197 - val_accuracy: 0.8006\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.7593e-07 - accuracy: 1.0000 - val_loss: 2.2211 - val_accuracy: 0.8006\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.7313e-07 - accuracy: 1.0000 - val_loss: 2.2229 - val_accuracy: 0.8020\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.7040e-07 - accuracy: 1.0000 - val_loss: 2.2247 - val_accuracy: 0.8020\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.6767e-07 - accuracy: 1.0000 - val_loss: 2.2261 - val_accuracy: 0.8020\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.6499e-07 - accuracy: 1.0000 - val_loss: 2.2279 - val_accuracy: 0.8020\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.6231e-07 - accuracy: 1.0000 - val_loss: 2.2293 - val_accuracy: 0.8020\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.5966e-07 - accuracy: 1.0000 - val_loss: 2.2309 - val_accuracy: 0.8020\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.5706e-07 - accuracy: 1.0000 - val_loss: 2.2322 - val_accuracy: 0.8006\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.5445e-07 - accuracy: 1.0000 - val_loss: 2.2342 - val_accuracy: 0.8020\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.5188e-07 - accuracy: 1.0000 - val_loss: 2.2357 - val_accuracy: 0.8020\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.4935e-07 - accuracy: 1.0000 - val_loss: 2.2370 - val_accuracy: 0.8020\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.4682e-07 - accuracy: 1.0000 - val_loss: 2.2386 - val_accuracy: 0.8020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.4432e-07 - accuracy: 1.0000 - val_loss: 2.2402 - val_accuracy: 0.8020\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.4183e-07 - accuracy: 1.0000 - val_loss: 2.2419 - val_accuracy: 0.8020\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.3938e-07 - accuracy: 1.0000 - val_loss: 2.2436 - val_accuracy: 0.8020\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.3695e-07 - accuracy: 1.0000 - val_loss: 2.2451 - val_accuracy: 0.8020\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.3456e-07 - accuracy: 1.0000 - val_loss: 2.2467 - val_accuracy: 0.8020\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.3216e-07 - accuracy: 1.0000 - val_loss: 2.2482 - val_accuracy: 0.8020\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.2979e-07 - accuracy: 1.0000 - val_loss: 2.2499 - val_accuracy: 0.8020\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.2743e-07 - accuracy: 1.0000 - val_loss: 2.2513 - val_accuracy: 0.8020\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.2510e-07 - accuracy: 1.0000 - val_loss: 2.2529 - val_accuracy: 0.8020\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.2278e-07 - accuracy: 1.0000 - val_loss: 2.2547 - val_accuracy: 0.8020\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.2047e-07 - accuracy: 1.0000 - val_loss: 2.2562 - val_accuracy: 0.8035\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.1820e-07 - accuracy: 1.0000 - val_loss: 2.2580 - val_accuracy: 0.8035\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 2.1594e-07 - accuracy: 1.0000 - val_loss: 2.2595 - val_accuracy: 0.8035\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.1371e-07 - accuracy: 1.0000 - val_loss: 2.2610 - val_accuracy: 0.8035\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.1148e-07 - accuracy: 1.0000 - val_loss: 2.2628 - val_accuracy: 0.8020\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.0929e-07 - accuracy: 1.0000 - val_loss: 2.2644 - val_accuracy: 0.8035\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.0710e-07 - accuracy: 1.0000 - val_loss: 2.2658 - val_accuracy: 0.8035\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.0494e-07 - accuracy: 1.0000 - val_loss: 2.2676 - val_accuracy: 0.8035\n",
      "Epoch 131/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.0280e-07 - accuracy: 1.0000 - val_loss: 2.2692 - val_accuracy: 0.8035\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.0068e-07 - accuracy: 1.0000 - val_loss: 2.2710 - val_accuracy: 0.8049\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.9855e-07 - accuracy: 1.0000 - val_loss: 2.2726 - val_accuracy: 0.8049\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.9646e-07 - accuracy: 1.0000 - val_loss: 2.2742 - val_accuracy: 0.8049\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.9437e-07 - accuracy: 1.0000 - val_loss: 2.2760 - val_accuracy: 0.8049\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.9230e-07 - accuracy: 1.0000 - val_loss: 2.2775 - val_accuracy: 0.8049\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.9025e-07 - accuracy: 1.0000 - val_loss: 2.2792 - val_accuracy: 0.8049\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.8821e-07 - accuracy: 1.0000 - val_loss: 2.2808 - val_accuracy: 0.8049\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.8618e-07 - accuracy: 1.0000 - val_loss: 2.2826 - val_accuracy: 0.8049\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.8418e-07 - accuracy: 1.0000 - val_loss: 2.2842 - val_accuracy: 0.8049\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.8219e-07 - accuracy: 1.0000 - val_loss: 2.2857 - val_accuracy: 0.8049\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.8027e-07 - accuracy: 1.0000 - val_loss: 2.2880 - val_accuracy: 0.8049\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.7843e-07 - accuracy: 1.0000 - val_loss: 2.2895 - val_accuracy: 0.8049\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.7663e-07 - accuracy: 1.0000 - val_loss: 2.2910 - val_accuracy: 0.8049\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.7488e-07 - accuracy: 1.0000 - val_loss: 2.2924 - val_accuracy: 0.8049\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.7315e-07 - accuracy: 1.0000 - val_loss: 2.2937 - val_accuracy: 0.8049\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.7144e-07 - accuracy: 1.0000 - val_loss: 2.2954 - val_accuracy: 0.8049\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.6976e-07 - accuracy: 1.0000 - val_loss: 2.2968 - val_accuracy: 0.8049\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.6810e-07 - accuracy: 1.0000 - val_loss: 2.2984 - val_accuracy: 0.8049\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.6646e-07 - accuracy: 1.0000 - val_loss: 2.2999 - val_accuracy: 0.8049\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.6484e-07 - accuracy: 1.0000 - val_loss: 2.3014 - val_accuracy: 0.8049\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.6323e-07 - accuracy: 1.0000 - val_loss: 2.3029 - val_accuracy: 0.8049\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.6164e-07 - accuracy: 1.0000 - val_loss: 2.3045 - val_accuracy: 0.8049\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.6007e-07 - accuracy: 1.0000 - val_loss: 2.3059 - val_accuracy: 0.8049\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.5851e-07 - accuracy: 1.0000 - val_loss: 2.3074 - val_accuracy: 0.8049\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.5697e-07 - accuracy: 1.0000 - val_loss: 2.3088 - val_accuracy: 0.8049\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.5545e-07 - accuracy: 1.0000 - val_loss: 2.3103 - val_accuracy: 0.8049\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.5394e-07 - accuracy: 1.0000 - val_loss: 2.3119 - val_accuracy: 0.8049\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.5245e-07 - accuracy: 1.0000 - val_loss: 2.3138 - val_accuracy: 0.8049\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.5097e-07 - accuracy: 1.0000 - val_loss: 2.3151 - val_accuracy: 0.8049\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4951e-07 - accuracy: 1.0000 - val_loss: 2.3164 - val_accuracy: 0.8049\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4807e-07 - accuracy: 1.0000 - val_loss: 2.3181 - val_accuracy: 0.8049\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4662e-07 - accuracy: 1.0000 - val_loss: 2.3195 - val_accuracy: 0.8049\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4521e-07 - accuracy: 1.0000 - val_loss: 2.3209 - val_accuracy: 0.8049\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4381e-07 - accuracy: 1.0000 - val_loss: 2.3224 - val_accuracy: 0.8049\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4242e-07 - accuracy: 1.0000 - val_loss: 2.3240 - val_accuracy: 0.8049\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.4104e-07 - accuracy: 1.0000 - val_loss: 2.3254 - val_accuracy: 0.8049\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3968e-07 - accuracy: 1.0000 - val_loss: 2.3268 - val_accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3833e-07 - accuracy: 1.0000 - val_loss: 2.3284 - val_accuracy: 0.8049\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3700e-07 - accuracy: 1.0000 - val_loss: 2.3296 - val_accuracy: 0.8049\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3567e-07 - accuracy: 1.0000 - val_loss: 2.3312 - val_accuracy: 0.8049\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3435e-07 - accuracy: 1.0000 - val_loss: 2.3328 - val_accuracy: 0.8049\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3303e-07 - accuracy: 1.0000 - val_loss: 2.3343 - val_accuracy: 0.8049\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.3174e-07 - accuracy: 1.0000 - val_loss: 2.3357 - val_accuracy: 0.8049\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.3045e-07 - accuracy: 1.0000 - val_loss: 2.3371 - val_accuracy: 0.8049\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.2918e-07 - accuracy: 1.0000 - val_loss: 2.3387 - val_accuracy: 0.8049\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.2792e-07 - accuracy: 1.0000 - val_loss: 2.3401 - val_accuracy: 0.8049\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2666e-07 - accuracy: 1.0000 - val_loss: 2.3417 - val_accuracy: 0.8049\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2542e-07 - accuracy: 1.0000 - val_loss: 2.3431 - val_accuracy: 0.8049\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2419e-07 - accuracy: 1.0000 - val_loss: 2.3445 - val_accuracy: 0.8049\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2296e-07 - accuracy: 1.0000 - val_loss: 2.3458 - val_accuracy: 0.8049\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2174e-07 - accuracy: 1.0000 - val_loss: 2.3474 - val_accuracy: 0.8049\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.2055e-07 - accuracy: 1.0000 - val_loss: 2.3490 - val_accuracy: 0.8049\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1935e-07 - accuracy: 1.0000 - val_loss: 2.3504 - val_accuracy: 0.8049\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.1816e-07 - accuracy: 1.0000 - val_loss: 2.3521 - val_accuracy: 0.8049\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1697e-07 - accuracy: 1.0000 - val_loss: 2.3536 - val_accuracy: 0.8049\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1581e-07 - accuracy: 1.0000 - val_loss: 2.3550 - val_accuracy: 0.8049\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1465e-07 - accuracy: 1.0000 - val_loss: 2.3569 - val_accuracy: 0.8049\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1349e-07 - accuracy: 1.0000 - val_loss: 2.3584 - val_accuracy: 0.8049\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1234e-07 - accuracy: 1.0000 - val_loss: 2.3597 - val_accuracy: 0.8049\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1120e-07 - accuracy: 1.0000 - val_loss: 2.3615 - val_accuracy: 0.8049\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.1007e-07 - accuracy: 1.0000 - val_loss: 2.3630 - val_accuracy: 0.8049\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0895e-07 - accuracy: 1.0000 - val_loss: 2.3645 - val_accuracy: 0.8049\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0784e-07 - accuracy: 1.0000 - val_loss: 2.3662 - val_accuracy: 0.8049\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0673e-07 - accuracy: 1.0000 - val_loss: 2.3676 - val_accuracy: 0.8049\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0564e-07 - accuracy: 1.0000 - val_loss: 2.3694 - val_accuracy: 0.8049\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0455e-07 - accuracy: 1.0000 - val_loss: 2.3709 - val_accuracy: 0.8049\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0347e-07 - accuracy: 1.0000 - val_loss: 2.3723 - val_accuracy: 0.8049\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.0239e-07 - accuracy: 1.0000 - val_loss: 2.3740 - val_accuracy: 0.8049\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.0133e-07 - accuracy: 1.0000 - val_loss: 2.3758 - val_accuracy: 0.8049\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                             epochs=200,\n",
    "                             validation_data=(X_test, y_test),\n",
    "                             batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 0s 2ms/step - loss: 1.0075e-07 - accuracy: 1.0000\n",
      "loss: 1.0074977296881116e-07, accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "print('loss: {}, accuracy: {}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 2.3757 - accuracy: 0.8049\n",
      "loss: 2.3757476806640625, accuracy: 0.8049490451812744\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print('loss: {}, accuracy: {}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    \n",
    "    x = range(1, len(acc) + 1) #200 1--200\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training Loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
